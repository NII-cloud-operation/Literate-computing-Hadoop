## 前提1: HDFSが利用可能(正常に読み書きできる)であること

- hosts: hadoop_spark_history
  sudo: yes
  sudo_user: spark
  tasks:
    - name: check_status_spark_history_server
      shell: '[ -s ${SPARK_PID_DIR}/spark-spark-org.apache.spark.deploy.history.HistoryServer-1.pid ] && [ -x /proc/$(cat ${SPARK_PID_DIR}/spark-spark-org.apache.spark.deploy.history.HistoryServer-1.pid ) ]'
      register: check_status_spark_history_server
      changed_when: false
      failed_when: check_status_spark_history_server.rc not in [0, 1]
      always_run: true

    - name: start_spark_history_server
      shell: \{{ ansible_env['SPARK_HOME'] }}/sbin/start-history-server.sh
      when: check_status_spark_history_server.rc != 0
      # Spark history serverは、PIDファイルが存在するがそのPIDのプロセスが存在しない、という状態でも問題なく起動できる。
      # そのため、上記チェックスクリプト実行後、PIDファイルが存在したら消す、というような処理を行う必要はない。
