- name: check_spark_installed
  stat: path={{ spark_install_path }}/spark-{{ spark_version }}-bin-{{ spark_hadoop_version }}
  register: check_spark_installed

- name: download_spark_by_wget
  shell: wget --no-verbose {{ spark_download_url }}/spark-{{ spark_version }}-bin-{{ spark_hadoop_version }}.tgz -O spark-{{ spark_version }}-bin-{{ spark_hadoop_version }}.tgz chdir={{ spark_tmp_path }} creates={{ spark_tmp_path }}/spark-{{ spark_version }}-bin-{{ spark_hadoop_version }}.tgz
  when: not check_spark_installed.stat.exists
  ignore_errors: yes

- name: get_md5sum_spark
  shell: md5sum {{ spark_tmp_path }}/spark-{{ spark_version }}-bin-{{ spark_hadoop_version }}.tgz
  when: not check_spark_installed.stat.exists
  register: md5sum_spark
  changed_when: false
  always_run: true

- name: check_spark_md5sum
  fail: "md5 check sum is not match. {{ md5sum_spark.stdout }} should be {{ spark_md5sum }}"
  when: not check_spark_installed.stat.exists and md5sum_spark.stdout.find('{{ spark_md5sum }}')

- name: umcompressed_spark.tgz_file
  sudo: yes
  shell: tar zxvf {{ spark_tmp_path }}/spark-{{ spark_version}}-bin-{{ spark_hadoop_version }}.tgz -C {{ spark_install_path }}
  when: not check_spark_installed.stat.exists

- name: change_spark_dir_onwer_to_root
  sudo: yes
  file: path={{ spark_install_path }} owner=root group=root recurse=yes state=directory
  when: not check_spark_installed.stat.exists

- name: delete_spark_logs_dir
  sudo: yes
  shell: rm -rf {{ spark_install_path }}/spark-{{ spark_version }}-bin-{{ spark_hadoop_version }}/logs
  when: not check_spark_installed.stat.exists
