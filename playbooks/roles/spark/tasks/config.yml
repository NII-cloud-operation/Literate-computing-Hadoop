- name: set_SPARK_HOME
  sudo: yes
  template: src=spark.sh.j2 dest=/etc/profile.d/spark.sh owner=root group=root mode=644
  
- name: create_spark_conf_dir
  sudo: yes
  file: path=/etc/spark/ state=directory owner=root group=root mode=755
  
- name: create_symbolic_link_to_spark_conf_dir
  sudo: yes
  file: path=/etc/spark/conf state=link src={{ spark_install_path }}/spark-{{ spark_version }}-bin-{{ spark_hadoop_version }}/conf
  when: hdp_version == '2.2.0.0-2041'

- include: principal.yml
  sudo: yes
  vars: { kerberos_princ_username: spark, kerberos_princ_keytab_path: /etc/spark/conf/spark.keytab, kerberos_princ_keytab_owner: spark }
  when: kerberos_realm is defined

- name: copy_spark_conf_files
  sudo: yes
  template: src={{ item }}.j2 dest=/etc/spark/conf/{{ item }} owner=root group=root mode=755
  with_items:
  - spark-defaults.conf
  - spark-env.sh
  - metrics.properties
  - log4j.properties
  - fairscheduler.xml

- name: copy_sudoers_conf_of_SPARK_HOME
  sudo: yes
  copy: src=env_keep_sparkhome dest=/etc/sudoers.d/ owner=root mode=440   
