{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About: Hadoop - Confirm the services are alive\n",
    "\n",
    "---\n",
    "\n",
    "Hadoop環境において以下のサービスが動作しているかの確認用Notebookです。\n",
    "\n",
    "- ZooKeeper\n",
    "- HDFS\n",
    "- YARN\n",
    "- HBase\n",
    "- Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Operation Note*\n",
    "\n",
    "*This is a cell for your own recording.  ここに経緯を記述*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 操作対象クラスタの設定\n",
    "\n",
    "**確認したい対象のクラスタ名**を以下のセルに記述してください。クラスタ名は *Set! Inventory Notebook* にて設定したAnsibleのグループ名で、 `hadoop_all_{{Cluster Name}}` のような形になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_group = 'hadoop_all_testcluster'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対象クラスタにAnsibleでpingできることを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.72 | SUCCESS => {\n",
      "    \"changed\": false, \n",
      "    \"ping\": \"pong\"\n",
      "}\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.71 | SUCCESS => {\n",
      "    \"changed\": false, \n",
      "    \"ping\": \"pong\"\n",
      "}\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.70 | SUCCESS => {\n",
      "    \"changed\": false, \n",
      "    \"ping\": \"pong\"\n",
      "}\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.112 | SUCCESS => {\n",
      "    \"changed\": false, \n",
      "    \"ping\": \"pong\"\n",
      "}\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.73 | SUCCESS => {\n",
      "    \"changed\": false, \n",
      "    \"ping\": \"pong\"\n",
      "}\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.113 | SUCCESS => {\n",
      "    \"changed\": false, \n",
      "    \"ping\": \"pong\"\n",
      "}\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.114 | SUCCESS => {\n",
      "    \"changed\": false, \n",
      "    \"ping\": \"pong\"\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ansible -m ping {target_group}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZooKeeperの状態確認\n",
    "\n",
    "サービスが起動しているか？\n",
    "\n",
    "ZooKeeperがインストールされたノードで `zookeeper-server is running` となればOK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.70 | SUCCESS | rc=0 >>\r\n",
      "zookeeper-server is running\r\n",
      "\u001b[0m\r\n",
      "\u001b[0;32mXXX.XXX.XXX.72 | SUCCESS | rc=0 >>\r\n",
      "zookeeper-server is running\r\n",
      "\u001b[0m\r\n",
      "\u001b[0;32mXXX.XXX.XXX.71 | SUCCESS | rc=0 >>\r\n",
      "zookeeper-server is running\r\n",
      "\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_zookeeperserver -b -a 'service zookeeper-server status' -l {target_group}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HDFSの状態確認\n",
    "\n",
    "NameNode, DataNode, JournalNodeの状態を確認する。\n",
    "\n",
    "## NameNodeの状態確認\n",
    "\n",
    "サービスが起動しているか？(rc=0ならばサービスが起動している)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZKFC:\n",
      "\u001b[0;32mXXX.XXX.XXX.70 | SUCCESS | rc=0 >>\n",
      "Hadoop zkfc is running[  OK  ]\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.71 | SUCCESS | rc=0 >>\n",
      "Hadoop zkfc is running[  OK  ]\n",
      "\u001b[0m\n",
      "NameNode:\n",
      "\u001b[0;32mXXX.XXX.XXX.70 | SUCCESS | rc=0 >>\n",
      "Hadoop namenode is running[  OK  ]\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.71 | SUCCESS | rc=0 >>\n",
      "Hadoop namenode is running[  OK  ]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# for NameNode-HA\n",
    "print(\"ZKFC:\")\n",
    "!ansible hadoop_namenode -s -a 'service hadoop-hdfs-zkfc status' -l {target_group}\n",
    "\n",
    "print(\"NameNode:\")\n",
    "!ansible hadoop_namenode -s -a 'service hadoop-hdfs-namenode status' -l {target_group}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HA構成の場合、サービスの状態は適切か？(どちらかがactiveになっているか？)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.71 | SUCCESS | rc=0 >>\n",
      "standby\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.70 | SUCCESS | rc=0 >>\n",
      "active\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_namenode -s -U hdfs -m shell \\\n",
    "         -a 'timeout 15 hdfs haadmin -getServiceState $(hostname)' -l {target_group}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataNodeの状態確認\n",
    "\n",
    "サービスが起動しているか？(rc=0ならばサービスが起動している)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.112 | SUCCESS | rc=0 >>\n",
      "Hadoop datanode is running[  OK  ]\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.73 | SUCCESS | rc=0 >>\n",
      "Hadoop datanode is running[  OK  ]\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.113 | SUCCESS | rc=0 >>\n",
      "Hadoop datanode is running[  OK  ]\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.114 | SUCCESS | rc=0 >>\n",
      "Hadoop datanode is running[  OK  ]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_slavenode -s -a 'service hadoop-hdfs-datanode status' -l {target_group}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataNode は Live Nodeとして認識されているか？\n",
    "\n",
    "Live datanodes の表示に、DataNodeの数が表示されていればOK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.72 | SUCCESS | rc=0 >>\r\n",
      "Configured Capacity: 422216597504 (393.22 GB)\r\n",
      "Present Capacity: 389015651549 (362.30 GB)\r\n",
      "DFS Remaining: 388823590109 (362.12 GB)\r\n",
      "DFS Used: 192061440 (183.16 MB)\r\n",
      "DFS Used%: 0.05%\r\n",
      "Under replicated blocks: 10\r\n",
      "Blocks with corrupt replicas: 0\r\n",
      "Missing blocks: 0\r\n",
      "Missing blocks (with replication factor 1): 0\r\n",
      "\r\n",
      "-------------------------------------------------\r\n",
      "Live datanodes (4):\r\n",
      "\r\n",
      "Name: XXX.XXX.XXX.114:50010 (testvm007)\r\n",
      "Hostname: testvm007\r\n",
      "Decommission Status : Normal\r\n",
      "Configured Capacity: 105554149376 (98.30 GB)\r\n",
      "DFS Used: 3772416 (3.60 MB)\r\n",
      "Non DFS Used: 8199401223 (7.64 GB)\r\n",
      "DFS Remaining: 97350975737 (90.67 GB)\r\n",
      "DFS Used%: 0.00%\r\n",
      "DFS Remaining%: 92.23%\r\n",
      "Configured Cache Capacity: 0 (0 B)\r\n",
      "Cache Used: 0 (0 B)\r\n",
      "Cache Remaining: 0 (0 B)\r\n",
      "Cache Used%: 100.00%\r\n",
      "Cache Remaining%: 0.00%\r\n",
      "Xceivers: 7\r\n",
      "Last contact: Fri Aug 19 11:47:02 JST 2016\r\n",
      "\r\n",
      "\r\n",
      "Name: XXX.XXX.XXX.73:50010 (testvm004)\r\n",
      "Hostname: testvm004\r\n",
      "Decommission Status : Normal\r\n",
      "Configured Capacity: 105554149376 (98.30 GB)\r\n",
      "DFS Used: 62947328 (60.03 MB)\r\n",
      "Non DFS Used: 8468164193 (7.89 GB)\r\n",
      "DFS Remaining: 97023037855 (90.36 GB)\r\n",
      "DFS Used%: 0.06%\r\n",
      "DFS Remaining%: 91.92%\r\n",
      "Configured Cache Capacity: 0 (0 B)\r\n",
      "Cache Used: 0 (0 B)\r\n",
      "Cache Remaining: 0 (0 B)\r\n",
      "Cache Used%: 100.00%\r\n",
      "Cache Remaining%: 0.00%\r\n",
      "Xceivers: 11\r\n",
      "Last contact: Fri Aug 19 11:47:01 JST 2016\r\n",
      "\r\n",
      "\r\n",
      "Name: XXX.XXX.XXX.112:50010 (testvm005)\r\n",
      "Hostname: testvm005\r\n",
      "Decommission Status : Normal\r\n",
      "Configured Capacity: 105554149376 (98.30 GB)\r\n",
      "DFS Used: 62664704 (59.76 MB)\r\n",
      "Non DFS Used: 8333942452 (7.76 GB)\r\n",
      "DFS Remaining: 97157542220 (90.49 GB)\r\n",
      "DFS Used%: 0.06%\r\n",
      "DFS Remaining%: 92.05%\r\n",
      "Configured Cache Capacity: 0 (0 B)\r\n",
      "Cache Used: 0 (0 B)\r\n",
      "Cache Remaining: 0 (0 B)\r\n",
      "Cache Used%: 100.00%\r\n",
      "Cache Remaining%: 0.00%\r\n",
      "Xceivers: 9\r\n",
      "Last contact: Fri Aug 19 11:47:02 JST 2016\r\n",
      "\r\n",
      "\r\n",
      "Name: XXX.XXX.XXX.113:50010 (testvm006)\r\n",
      "Hostname: testvm006\r\n",
      "Decommission Status : Normal\r\n",
      "Configured Capacity: 105554149376 (98.30 GB)\r\n",
      "DFS Used: 62676992 (59.77 MB)\r\n",
      "Non DFS Used: 8199438087 (7.64 GB)\r\n",
      "DFS Remaining: 97292034297 (90.61 GB)\r\n",
      "DFS Used%: 0.06%\r\n",
      "DFS Remaining%: 92.17%\r\n",
      "Configured Cache Capacity: 0 (0 B)\r\n",
      "Cache Used: 0 (0 B)\r\n",
      "Cache Remaining: 0 (0 B)\r\n",
      "Cache Used%: 100.00%\r\n",
      "Cache Remaining%: 0.00%\r\n",
      "Xceivers: 7\r\n",
      "Last contact: Fri Aug 19 11:47:03 JST 2016\r\n",
      "\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_client -s -U hdfs -a 'hdfs dfsadmin -report' -l {target_group}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JournalNodeの状態確認 - HA構成の場合\n",
    "\n",
    "サービスが起動しているか？(rc=0ならばサービスが起動している)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.72 | SUCCESS | rc=0 >>\r\n",
      "Hadoop journalnode is running[  OK  ]\r\n",
      "\u001b[0m\r\n",
      "\u001b[0;32mXXX.XXX.XXX.71 | SUCCESS | rc=0 >>\r\n",
      "Hadoop journalnode is running[  OK  ]\r\n",
      "\u001b[0m\r\n",
      "\u001b[0;32mXXX.XXX.XXX.70 | SUCCESS | rc=0 >>\r\n",
      "Hadoop journalnode is running[  OK  ]\r\n",
      "\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_journalnode -s -a 'service hadoop-hdfs-journalnode status' -l {target_group}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDFSのWeb UIの確認\n",
    "\n",
    "以下のURLから、Web UIが確認できることをチェックする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://XXX.XXX.XXX.70:50070/\n"
     ]
    }
   ],
   "source": [
    "## for Single Node Cluster\n",
    "# import re\n",
    "# ping_stdout = !ansible hadoop_namenode -s -U hdfs -m ping -l {target_group}\n",
    "# namenode_addr = filter(lambda m: m, map(lambda l: re.match(r'^(\\S+)\\s*\\|\\s*SUCCESS\\s+', l), ping_stdout))[0].group(1)\n",
    "\n",
    "# for NameNode-HA\n",
    "haadmin_stdout = !ansible hadoop_namenode -s -U hdfs -m shell -a 'timeout 15 hdfs haadmin -getServiceState $(hostname)' -l {target_group}\n",
    "haadmin_result = [line.split()[0] for line in haadmin_stdout if len(line) > 0]\n",
    "namenode_addr = haadmin_result[haadmin_result.index(\"active\") - 1]\n",
    "\n",
    "print(\"http://%s:50070/\" % namenode_addr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YARNの状態確認\n",
    "\n",
    "ResourceManager, NodeManager, MapReduce HistoryServerの状態を確認する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResourceManagerの状態確認\n",
    "\n",
    "サービスが起動しているか？(rc=0ならばサービスが起動している)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.71 | SUCCESS | rc=0 >>\r\n",
      "Hadoop resourcemanager is running[  OK  ]/etc/default/hadoop-yarn-resourcemanager: line 21: unexpected EOF while looking for matching `\"'\r\n",
      "/etc/default/hadoop-yarn-resourcemanager: line 23: syntax error: unexpected end of file\r\n",
      "\u001b[0m\r\n",
      "\u001b[0;32mXXX.XXX.XXX.70 | SUCCESS | rc=0 >>\r\n",
      "Hadoop resourcemanager is running[  OK  ]/etc/default/hadoop-yarn-resourcemanager: line 21: unexpected EOF while looking for matching `\"'\r\n",
      "/etc/default/hadoop-yarn-resourcemanager: line 23: syntax error: unexpected end of file\r\n",
      "\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_resourcemanager -s -a 'service hadoop-yarn-resourcemanager status' -l {target_group}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HA構成の場合、サービスの状態は適切か？(必ずどちらかがactiveになっているか？)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.70 | SUCCESS | rc=0 >>\n",
      "active\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.71 | SUCCESS | rc=0 >>\n",
      "standby\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_resourcemanager -s -U yarn -m shell \\\n",
    "         -a 'timeout 15 yarn rmadmin -getServiceState $(hostname)' -l {target_group}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NodeManagerの状態確認\n",
    "\n",
    "サービスが起動しているか？(rc=0ならばサービスが起動している)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.112 | SUCCESS | rc=0 >>\n",
      "Hadoop nodemanager is running[  OK  ]\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.113 | SUCCESS | rc=0 >>\n",
      "Hadoop nodemanager is running[  OK  ]\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.73 | SUCCESS | rc=0 >>\n",
      "Hadoop nodemanager is running[  OK  ]\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.114 | SUCCESS | rc=0 >>\n",
      "Hadoop nodemanager is running[  OK  ]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_slavenode -s -a 'service hadoop-yarn-nodemanager status' -l {target_group}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NodeManagerはResourceManagerによって認識されているか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.70 | SUCCESS | rc=0 >>\r\n",
      "Total Nodes:4\r\n",
      "         Node-Id\t     Node-State\tNode-Http-Address\tNumber-of-Running-Containers\r\n",
      " testvm007:45454\t        RUNNING\t   testvm007:8042\t                           0\r\n",
      " testvm006:45454\t        RUNNING\t   testvm006:8042\t                           0\r\n",
      " testvm005:45454\t        RUNNING\t   testvm005:8042\t                           0\r\n",
      " testvm004:45454\t        RUNNING\t   testvm004:8042\t                           016/08/19 11:48:57 INFO impl.TimelineClientImpl: Timeline service address: http://testvm003:8188/ws/v1/timeline/\r\n",
      "\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "## for Single Node Cluster\n",
    "# import re\n",
    "# ping_stdout = !ansible hadoop_resourcemanager -s -U hdfs -m ping -l {target_group}\n",
    "# resourcemanager_addr = filter(lambda m: m, map(lambda l: re.match(r'^(\\S+)\\s*\\|\\s*SUCCESS\\s+', l), ping_stdout))[0].group(1)\n",
    "\n",
    "# for ResourceManager-HA\n",
    "rmadmin_stdout = !ansible hadoop_resourcemanager -s -U yarn -m shell -a 'timeout 15 yarn rmadmin -getServiceState $(hostname)'\n",
    "rmadmin_result = [line.split()[0] for line in rmadmin_stdout if len(line) > 0]\n",
    "resourcemanager_addr = rmadmin_result[rmadmin_result.index(\"active\") - 1]\n",
    "\n",
    "!ansible {resourcemanager_addr} -s -U yarn -a \"timeout 15 yarn node -list\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce HistoryServerの状態確認\n",
    "\n",
    "MapReduce HistoryServerを利用している場合・・・サービスが起動しているか？(rc=0ならばサービスが起動している)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.72 | SUCCESS | rc=0 >>\r\n",
      "Hadoop historyserver is running[  OK  ]\r\n",
      "\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_mapreduce_historyserver -s -a 'service hadoop-mapreduce-historyserver status' -l {target_group}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YARNのWeb UIの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://XXX.XXX.XXX.70:8088/\n"
     ]
    }
   ],
   "source": [
    "## for Single Node Cluster\n",
    "#import re\n",
    "#ping_stdout = !ansible hadoop_resourcemanager -s -U hdfs -m ping -l {target_group}\n",
    "#resourcemanager_addr = filter(lambda m: m, map(lambda l: re.match(r'^(\\S+)\\s*\\|\\s*SUCCESS\\s+', l), ping_stdout))[0].group(1)\n",
    "\n",
    "# for ResourceManager-HA\n",
    "rmadmin_stdout = !ansible hadoop_resourcemanager -s -U yarn -m shell -a 'timeout 15 yarn rmadmin -getServiceState $(hostname)'\n",
    "rmadmin_result = [line.split()[0] for line in rmadmin_stdout if len(line) > 0]\n",
    "resourcemanager_addr = rmadmin_result[rmadmin_result.index(\"active\") - 1]\n",
    "\n",
    "print(\"http://%s:8088/\" % resourcemanager_addr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBaseの状態確認\n",
    "\n",
    "Master, RegionServerの状態を確認する。\n",
    "\n",
    "## Masterの状態確認\n",
    "\n",
    "サービスが起動しているか？(rc=0ならばサービスが起動している)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.71 | SUCCESS | rc=0 >>\r\n",
      "HBase master daemon is running[  OK  ]\r\n",
      "\u001b[0m\r\n",
      "\u001b[0;32mXXX.XXX.XXX.70 | SUCCESS | rc=0 >>\r\n",
      "HBase master daemon is running[  OK  ]\r\n",
      "\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_hbase_master -l {target_group} -b -a 'service hbase-master status'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RegionServerの状態確認\n",
    "\n",
    "サービスが起動しているか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.113 | SUCCESS | rc=0 >>\n",
      "hbase-regionserver is running\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.73 | SUCCESS | rc=0 >>\n",
      "hbase-regionserver is running\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.112 | SUCCESS | rc=0 >>\n",
      "hbase-regionserver is running\n",
      "\u001b[0m\n",
      "\u001b[0;32mXXX.XXX.XXX.114 | SUCCESS | rc=0 >>\n",
      "hbase-regionserver is running\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_hbase_regionserver -l {target_group} -b -a 'service hbase-regionserver status'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## HBaseのWeb UIの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'testvm001': 'XXX.XXX.XXX.70',\n",
       " 'testvm002': 'XXX.XXX.XXX.71',\n",
       " 'testvm003': 'XXX.XXX.XXX.72',\n",
       " 'testvm004': 'XXX.XXX.XXX.73',\n",
       " 'testvm005': 'XXX.XXX.XXX.112',\n",
       " 'testvm006': 'XXX.XXX.XXX.113',\n",
       " 'testvm007': 'XXX.XXX.XXX.114'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hosts_stdout = !ansible {target_group} -b -a 'cat /etc/hosts'\n",
    "hosts_stdout = filter(lambda l: not l.strip().endswith('>>'), hosts_stdout)\n",
    "hosts_stdout = map(lambda l: l.split(), hosts_stdout)\n",
    "hosts_stdout = filter(lambda l: len(l) == 2, hosts_stdout)\n",
    "machines = dict(map(lambda l: (l[1], l[0]), hosts_stdout))\n",
    "machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://XXX.XXX.XXX.70:60010\n"
     ]
    }
   ],
   "source": [
    "zknode_stdout = !ansible -m ping -l {target_group} hadoop_zookeeperserver\n",
    "zknodes = sorted([l.split()[0] for l in zknode_stdout if 'SUCCESS' in l])\n",
    "\n",
    "from kazoo.client import KazooClient\n",
    "zk = KazooClient(hosts='%s:2181' % zknodes[0], read_only=True)\n",
    "zk.start()\n",
    "(master_result,v) = zk.get(\"/hbase/master\")\n",
    "zk.stop()\n",
    "for host, ip in machines.items():\n",
    "    if host in master_result:\n",
    "        hbase_master_host = ip\n",
    "print(\"http://%s:60010\" % hbase_master_host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark HistoryServer\n",
    "\n",
    "サービスが起動しているか？(rc=0ならばサービスが起動している)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mXXX.XXX.XXX.72 | SUCCESS | rc=0 >>\r\n",
      "\r\n",
      "\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!ansible hadoop_spark_history -l {target_group} -b --become-user spark -m shell \\\n",
    "         -a '[ -s ${{SPARK_PID_DIR}}/spark-spark-org.apache.spark.deploy.history.HistoryServer-1.pid ] && [ -x /proc/$(cat ${{SPARK_PID_DIR}}/spark-spark-org.apache.spark.deploy.history.HistoryServer-1.pid ) ]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
